module Parsing.Parser;

import Tokenizer := Parsing.Tokenizer;
import Ast := Syntax.Ast;
import Util;
import Env := Syntax.Env;

class Parser where 
    val tokens : Tokenizer.Token[];
    var pos : Number;

    val undesugared_exprs : Ast.Mut(Ast.Expr)[] := [];
    val undesugared_decls : Ast.Mut(Ast.Decl)[] := [];

    new(source : String) do
        this.tokens := Tokenizer.tokenize_all(source);
        this.pos := 0;
    end;

    fun next() : Tokenizer.Token do 
        val token := this.tokens[this.pos];
        this.pos := this.pos + 1;
        token
    end

    fun peek() : Tokenizer.Token := this.tokens[this.pos];
    fun peekNext() : Tokenizer.Token := this.tokens[this.pos+1];

    fun consume(t : Tokenizer.TokenType, error : String) : Tokenizer.Token do 
        val nxt := this.next();
        if nxt.kind != t do
            panic("["+(nxt.pos.line+1)+":"+nxt.pos.collumn+"]: Unexpected "+nxt.kind+": "+error);
        end;
        nxt
    end

    fun matches_type(t : Tokenizer.TokenType) : Bool do 
        if this.peek().kind = t then do 
            this.pos := this.pos + 1;
            true
        end else do 
            false
        end
    end

    fun previous() : Tokenizer.Token := this.tokens[this.pos - 1];
    fun at_end() : Bool := this.peek().kind = Tokenizer.EOF();

    fun wrap_sugared_expr(e : Ast.Expr) : Ast.Expr := do 
        val mut_expr := Ast.Mut.[Ast.Expr](e);
        this.undesugared_exprs.push(mut_expr);
        Ast.DesugarableExpr(mut_expr)
    end;
    fun wrap_sugared_decl(d : Ast.Decl) : Ast.Decl := do 
        val mut_decl  := Ast.Mut.[Ast.Decl](d);
        this.undesugared_decls.push(mut_decl);
        Ast.DesugarableDecl(mut_decl)
    end;

    fun err(str: String): String do 
        val nxt := this.peek();
        "["+(nxt.pos.line+1)+":"+nxt.pos.collumn+"]:"+str
    end
end;

fun parse(source : String) : (Ast.Program, (Ast.Mut(Ast.Expr)[], Ast.Mut(Ast.Decl)[])) do 
    val parser := Parser(source);
    val prg := program(parser); 
    (prg, (parser.undesugared_exprs, parser.undesugared_decls))
end

fun program(p : Parser) : Ast.Program do 
    val prgm := Ast.Program();
    if p.matches_type(Tokenizer.MODULE()) do 
        p.consume(Tokenizer.IDENTIFIER(), "Expect module name after module declaration");
        while p.matches_type(Tokenizer.DOT()) do 
            p.consume(Tokenizer.IDENTIFIER(), "Expect submodule name after '.'");
        end;
        p.consume(Tokenizer.SEMICOLON(), "Expect ';' after module declaration");
    end
    while p.matches_type(Tokenizer.IMPORT()) do 
        prgm.imports.push(import_decl(p));
    end;
    while !p.at_end() do 
        prgm.decls.push(decl(p));
    end;
    prgm
end

fun import_decl(p : Parser) : Ast.Import do 
    val parts : String[] := [];
    parts.push(p.consume(Tokenizer.IDENTIFIER(), "Expect identifier as beginning of path after 'import'").src);
    while p.matches_type(Tokenizer.DOT()) do 
        parts.push(p.consume(Tokenizer.IDENTIFIER(), "Expect identifier after '.'").src);
    end;
    if p.matches_type(Tokenizer.ASSIGN()) then do 
        if parts.length != 1 do panic(p.err("Expected single name as import alias, got complex name: "+parts)); end;
        val alias_name := parts[0];
        val imported_parts : String[] := [];
        imported_parts.push(p.consume(Tokenizer.IDENTIFIER(), "Expect identifier as beginnning of path after ':='").src);
        while p.matches_type(Tokenizer.DOT()) do 
            imported_parts.push(p.consume(Tokenizer.IDENTIFIER(), "Expect identifier after '.'").src);
        end;
        p.consume(Tokenizer.SEMICOLON(), "Expect ';' after import declaration");
        Ast.AliasImport(alias_name, imported_parts)
    end else do
        p.consume(Tokenizer.SEMICOLON(), "Expect ';' after import declaration");
        Ast.BasicImport(parts)
    end
end

fun stmt(p : Parser) : Ast.Stmt do 
    val nxt := p.peek();
    if is_decl_start(p) do 
        return Ast.Declaration(decl(p));
    end;
    if val SEMICOLON() := nxt.kind then do 
        p.next();
        Ast.EmptyStmt()
    end else if val IF() := nxt.kind then do 
        val pos := p.pos;
        p.next();
        val cond := expr(p);
        if p.matches_type(Tokenizer.DO()) then do 
            val body := block_expr(p);
            Ast.IfStmt(cond, body)
        end else do 
            p.pos := pos;
            Ast.ExprStmt(expr(p))
        end
    end else do 
        val arg := expr(p);
        if p.matches_type(Tokenizer.ASSIGN()) then do 
            assign_stmt_to(p, arg)
        end else do 
            p.consume(Tokenizer.SEMICOLON(), "Expect ';' after expression statement");
            Ast.ExprStmt(arg)
        end
    end
end

fun is_decl_start(p : Parser) : Bool := match p.peek().kind do 
    case VAL() := true;
    case VAR() := true;
    case FUN() := p.peekNext().kind = Tokenizer.IDENTIFIER();
    case CLASS() := true;
    case ENUM() := true;
    case ? := false;
end;

fun decl(p : Parser) : Ast.Decl do 
    val decl_kind := p.next().kind;
    match decl_kind do 
        case MODULE() := do 
            panic("Did not consume Module declaration, parser state: "+p.pos+" previous: "+p.previous().kind)
        end;
        case VAR() := var_decl(p, true);
        case VAL() := var_decl(p, false);
        case FUN() := fun_decl(p);
        case CLASS() := class_decl(p);
        case ENUM() := enum_decl(p);
        case SEMICOLON() := Ast.EmptyDecl();
    end
end

fun enum_decl(p : Parser) : Ast.Decl do 
    val name := p.consume(Tokenizer.IDENTIFIER(), "Expect class name after 'class' keyword");
    val targs := if p.matches_type(Tokenizer.LPAREN()) then do 
        val params: Ast.TypeParameter[] := [];
        var needs_comma := false;
        while !p.matches_type(Tokenizer.RPAREN()) do 
            if needs_comma do p.consume(Tokenizer.COMMA(), "Expect ',' to separate type parameters"); end;
            val param_name := p.consume(Tokenizer.IDENTIFIER(), "Expect type parameter name");
            params.push(Ast.TypeParameter(param_name.src));
            needs_comma := true;
        end;
        params
    end else [];
    p.consume(Tokenizer.WHERE(), "Expect start of enum body after enum name: 'where'");
    val constructors : Ast.EnumConstructor[] := [];
    var needs_comma := false;
    while !p.matches_type(Tokenizer.SEMICOLON()) do 
        if needs_comma do 
            p.consume(Tokenizer.COMMA(), "Expect ',' to separate enum variants");
        end;
        val constr_name := p.consume(Tokenizer.IDENTIFIER(), "Expect enum variant to start with identifier");
        p.consume(Tokenizer.LPAREN(), "Expect '(' after enum constructor name");
        val types : Ast.Type[] := [];
        var inner_needs_comma := false;
        while !p.matches_type(Tokenizer.RPAREN()) do 
            if inner_needs_comma do p.consume(Tokenizer.COMMA(), "Expect ',' to separate enum variant parameters"); end;
            types.push(type_literal(p));
            inner_needs_comma := true;
        end;
        constructors.push(Ast.EnumConstructor(constr_name.src, types));
        needs_comma := true;
    end;
    val members : Ast.Decl[] := [];
    while !p.matches_type(Tokenizer.END()) do 
        members.push(decl(p));
    end;
    Ast.EnumDecl(name.src, targs, constructors, members, true, Ast.late_namespace())
end

fun class_decl(p : Parser) : Ast.Decl do 
    val name := p.consume(Tokenizer.IDENTIFIER(), "Expect class name after 'class' keyword");
    val targs := if p.matches_type(Tokenizer.LPAREN()) then do 
        val params: Ast.TypeParameter[] := [];
        var needs_comma := false;
        while !p.matches_type(Tokenizer.RPAREN()) do 
            if needs_comma do p.consume(Tokenizer.COMMA(), "Expect ',' to separate type parameters"); end;
            val param_name := p.consume(Tokenizer.IDENTIFIER(), "Expect type parameter name");
            params.push(Ast.TypeParameter(param_name.src));
            needs_comma := true;
        end;
        params
    end else [];
    p.consume(Tokenizer.WHERE(), "Expect start of class body after class name: 'where'");
    val members : Ast.Decl[] := [];
    var constr : Optional(Ast.Constructor) := None.[Ast.Constructor]();
    while !p.matches_type(Tokenizer.END()) do 
        if p.matches_type(Tokenizer.NEW()) then do 
            if val Some(?) := constr then do 
                panic("Error: Class '"+name.src+"' can only have on constructor");
            end else do end;
            constr := Some.[Ast.Constructor](constructor(p));
        end else do 
            val member : Ast.Decl := decl(p);
            members.push(member);
        end;
    end;
    Ast.ClassDecl(name.src, targs, members, constr, true, Ast.late_namespace())
end

fun constructor(p : Parser) : Ast.Constructor do 
    val params := parse_parameters(p);
    p.consume(Tokenizer.DO(), "Expect do after end of constructor parameter declaration");
    val body := block_expr(p);
    Ast.Constructor(params, body)
end

fun fun_decl(p : Parser) : Ast.Decl do 
    val name := p.consume(Tokenizer.IDENTIFIER(), "Expect name in function declaration");
    val typarams : Ast.TypeParameter[] := if p.matches_type(Tokenizer.LBRACKET())
        then do 
            val params : Ast.TypeParameter[] := [];
            var needs_comma := false;
            while !p.matches_type(Tokenizer.RBRACKET()) do 
                if needs_comma do p.consume(Tokenizer.COMMA(), "Expect ',' to separate type parameters"); end;
                val param_name := p.consume(Tokenizer.IDENTIFIER(), "Expect type parameter name");
                params.push(Ast.TypeParameter(param_name.src));
                needs_comma := true;
            end;
            params
        end else [];
    val (params, return_type, body) := end_of_function(p, true);
    Ast.FunDecl(name.src, typarams, params, return_type, body, true, Ast.late_namespace())
end

fun parse_parameters(p : Parser) : Ast.Parameter[] do 
    p.consume(Tokenizer.LPAREN(), "Expect start of parameters in function declaration");
    val params : Ast.Parameter[] := [];
    while !p.matches_type(Tokenizer.RPAREN()) do 
        params.push(parameter(p));
        if p.peek().kind != Tokenizer.RPAREN() do 
            p.consume(Tokenizer.COMMA(), "Expect ',' between parameters");
        end;
    end;
    params
end

fun end_of_function(p : Parser, consume_semi : Bool) : (Ast.Parameter[], Ast.Type, Ast.Expr) do
    val params := parse_parameters(p);
    val return_type := if p.matches_type(Tokenizer.COLON()) 
        then type_literal(p)
        else Ast.VoidT();
    val body := if p.matches_type(Tokenizer.ASSIGN()) then do
        val b := expr(p);
        if consume_semi do 
            p.consume(Tokenizer.SEMICOLON(), "Expect ';' after function body");
        end
        b 
    end else do 
        p.consume(Tokenizer.DO(), "Expect ':=' or 'do' as start of function body");
        block_expr(p)
    end;
    (params, return_type, body)
end

fun parameter(p : Parser) : Ast.Parameter do 
    val name := p.consume(Tokenizer.IDENTIFIER(), "Expect parameter name");
    p.consume(Tokenizer.COLON(), "Expect ':' before parameter type");
    val param_type := type_literal(p);
    Ast.NormalParam(name.src, param_type)
end

fun var_decl(p : Parser, mutable : Bool) : Ast.Decl do 
    val keyword := p.previous();
    val setter_unconverted := expr(p);
    val ty := Ast.late_type();
    if p.matches_type(Tokenizer.COLON()) do 
        ty.init(type_literal(p));
    end;
    val initializer := if p.matches_type(Tokenizer.ASSIGN()) then do 
        Some.[Ast.Expr](expr(p))
    end else None.[Ast.Expr]();
    if p.matches_type(Tokenizer.ELSE()) then do 
        val else_br := expr(p);
        p.consume(Tokenizer.SEMICOLON(), "Expect ';' after variable declaration with else branch");
        p.wrap_sugared_decl(Ast.ValElseDeclaration(convert_pattern(setter_unconverted), initializer.expect("Require initializer in val-else declaration at "+keyword.pos.line), else_br, mutable, true, ty, 
                               Ast.late_type(), Ast.late_namespace()))
    end else do 
        p.consume(Tokenizer.SEMICOLON(), "Expect ';' after variable declaration");
        Ast.VarDecl(convert_setter(setter_unconverted), ty, initializer, mutable, true)
    end
end

fun expr(p : Parser) : Ast.Expr := boolean_combination(p);

fun boolean_combination(p : Parser) : Ast.Expr do 
    var lhs := comparison(p);
    while p.matches_type(Tokenizer.AND()) or p.matches_type(Tokenizer.OR()) or p.matches_type(Tokenizer.XOR()) do 
        val operator := p.previous();
        val rhs := comparison(p);
        val op := match operator.kind do 
            case AND() := Ast.And();
            case OR() := Ast.Or();
            case XOR() := Ast.Xor();
        end;
        lhs := Ast.BinaryOperation(op, lhs, rhs); 
    end;
    lhs
end

fun comparison(p : Parser) : Ast.Expr do 
    var result := addition(p);
    if p.matches_type(Tokenizer.LESS()) or 
       p.matches_type(Tokenizer.LESS_EQUAL()) or 
       p.matches_type(Tokenizer.EQUAL()) or 
       p.matches_type(Tokenizer.GREATER_EQUAL()) or 
       p.matches_type(Tokenizer.GREATER()) or 
       p.matches_type(Tokenizer.NOT_EQUAL()) 
    do 
        val operator := p.previous();
        val rhs := addition(p);
        val op := match operator.kind do 
            case LESS() := Ast.LessThan();
            case LESS_EQUAL() := Ast.LessEqual();
            case EQUAL() := Ast.Equals();
            case NOT_EQUAL() := Ast.NotEquals();
            case GREATER_EQUAL() := Ast.GreaterEqual();
            case GREATER() := Ast.GreaterThan();
        end;
        result := Ast.BinaryOperation(op, result, rhs);
    end;
    result
end

fun addition(p : Parser) : Ast.Expr do 
    var lhs := multiplication(p);
    while !p.at_end() and (p.matches_type(Tokenizer.PLUS()) or p.matches_type(Tokenizer.MINUS())) do 
        val op := p.previous().kind;
        val rhs := multiplication(p);
        lhs := Ast.BinaryOperation(match op do 
            case PLUS() := Ast.Add(Ast.late_type());
            case MINUS() := Ast.Sub();
        end, lhs, rhs);
    end;
    lhs
end

fun multiplication(p : Parser) : Ast.Expr do 
    var lhs := unary(p);
    while !p.at_end() and (p.matches_type(Tokenizer.STAR()) or p.matches_type(Tokenizer.SLASH()) or p.matches_type(Tokenizer.PERCENT())) do 
        val op := p.previous().kind;
        val rhs := unary(p);
        lhs := Ast.BinaryOperation(match op do 
            case STAR() := Ast.Mul();
            case PERCENT() := Ast.Mod();
            case SLASH() := Ast.Div();
        end, lhs, rhs);
    end;
    lhs
end

fun unary(p : Parser) : Ast.Expr := 
    if p.matches_type(Tokenizer.MINUS()) then do 
        val operand := unary(p);
        Ast.UnaryOperation(Ast.Minus(), operand)
    end else if p.matches_type(Tokenizer.PLUS()) then do 
        val operand := unary(p);
        Ast.UnaryOperation(Ast.Plus(), operand)
    end else if p.matches_type(Tokenizer.BANG()) then do 
        val operand := unary(p);
        Ast.UnaryOperation(Ast.Not(), operand)
    end else do 
        use_expr(p)
    end;

fun use_expr(p : Parser) : Ast.Expr do 
    var lhs := primary(p);
    while p.peek().kind = Tokenizer.LPAREN() or 
          p.peek().kind = Tokenizer.DOT() or 
          p.peek().kind = Tokenizer.LBRACKET() 
    do
        if p.peek().kind = Tokenizer.LPAREN() then do // Consume and test next token
            p.next();
            var arg_exprs : Ast.Expr[] := [];
            var needs_comma := false;
            while !p.matches_type(Tokenizer.RPAREN()) do 
                if needs_comma do 
                    p.consume(Tokenizer.COMMA(), "Expect parameters to be separated by commas");
                end;
                arg_exprs.push(expr(p));
                needs_comma := true;
            end;
            lhs := Ast.FunctionCall(lhs, arg_exprs);
        end else if p.peek().kind = Tokenizer.LBRACKET() then do
            p.next();
            val idx := expr(p);
            p.consume(Tokenizer.RBRACKET(), "Expect closing ']' in index expression");
            lhs := Ast.IndexExpr(lhs, idx, Ast.late_type());
        end else do
            p.next();
            if p.matches_type(Tokenizer.LBRACKET()) then do 
                val arg_tys : Ast.Type[] := [];
                var needs_comma := false;
                while !p.matches_type(Tokenizer.RBRACKET()) do 
                    if needs_comma do p.consume(Tokenizer.COMMA(), "Expect ',' to separate type parameters"); end
                    arg_tys.push(type_literal(p));
                    needs_comma := true;
                end;
                lhs := Ast.InstantiationExpr(lhs, arg_tys, Ast.late_type());
            end else do 
                val property := p.consume(Tokenizer.IDENTIFIER(), "Expect property name after .");
                lhs := Ast.PropertyExpr(lhs, property.src, 
                                    Util.LateInitialized.[Ast.AccessType](), Ast.late_type(), Ast.late_type());
            end;
        end
    end;
    lhs
end

fun primary(p : Parser) : Ast.Expr := 
    if p.matches_type(Tokenizer.IF()) then do 
        if_expr(p)    
    end else if p.matches_type(Tokenizer.DO()) then do 
        block_expr(p)
    end else if p.matches_type(Tokenizer.FOR()) then do 
        for_loop(p)
    end else if p.matches_type(Tokenizer.WHILE()) then do 
        while_loop(p)
    end else if p.matches_type(Tokenizer.MATCH()) then do 
        match_expr(p)
    end else if p.matches_type(Tokenizer.RETURN()) then do 
        val arg := expr(p);
        Ast.ReturnExpr(arg, Ast.late_type())
    end else if p.matches_type(Tokenizer.BREAK()) then do 
        Ast.Break(Ast.late_type())
    end else do 
        literal(p)
    end;

fun match_expr(p : Parser) : Ast.Expr do 
    val matched := expr(p);
    p.consume(Tokenizer.DO(), "Expect 'do' after matched expression");
    val cases : (Ast.Pattern, Ast.Expr, Util.LateInitialized(Ast.Namespace))[] := [];
    while !p.matches_type(Tokenizer.END()) do
        p.consume(Tokenizer.CASE(), "Expect 'case' to start pattern");
        val pat := pattern(p);
        p.consume(Tokenizer.ASSIGN(), "Expect ':=' after pattern");
        val result := expr(p);
        p.consume(Tokenizer.SEMICOLON(), "Expect ';' after case arm");
        cases.push((pat, result, Ast.late_namespace()));
    end;
    Ast.MatchExpr(matched, cases, Ast.late_type(), Ast.late_type())
end

fun pattern(p : Parser) : Ast.Pattern :=
    if p.matches_type(Tokenizer.NUMBER_LITERAL()) then do 
        val token := p.previous();
        Ast.NumericPattern(number(token.src))
    end else if p.matches_type(Tokenizer.STRING_LITERAL()) then do 
        val token := p.previous();
        Ast.StringPattern(token.src)
    end else if p.matches_type(Tokenizer.TRUE()) then do 
        Ast.BooleanPattern(true)
    end else if p.matches_type(Tokenizer.FALSE()) then do 
        Ast.BooleanPattern(false)
    end else if p.matches_type(Tokenizer.QUESTION_MARK()) then do 
        Ast.WildcardPattern()
    end else if p.matches_type(Tokenizer.LPAREN()) then do 
        val parts : Ast.Pattern[] := [];
        var needs_comma := false;
        while !p.matches_type(Tokenizer.RPAREN()) do 
            if needs_comma do p.consume(Tokenizer.COMMA(), "Expect comma to separate tuple pattern parts"); end;
            parts.push(pattern(p));
            needs_comma := true;
        end;
        Ast.TuplePattern(parts)
    end else if p.matches_type(Tokenizer.IDENTIFIER()) then do 
        val name := p.previous().src;
        if p.matches_type(Tokenizer.LPAREN()) then do 
            val parts : Ast.Pattern[] := [];
            var needs_comma := false;
            while !p.matches_type(Tokenizer.RPAREN()) do 
                if needs_comma do p.consume(Tokenizer.COMMA(), 
                    "Expect comma to separate constructor pattern parameters"); end;
                parts.push(pattern(p));
                needs_comma := true;
            end;
            Ast.ConstructorPattern(name, parts, Util.LateInitialized.[Ast.EnumConstructor](), Ast.late_type(), Util.LateInitialized.[Ast.TyInfo]())
        end else do 
            Ast.NamePattern(name)
        end
        
    end else do 
        panic("Unexpected "+p.next().kind+", expected start of pattern")
    end;


fun while_loop(p : Parser) : Ast.Expr do
    if p.matches_type(Tokenizer.VAL()) then do 
        val pat := pattern(p);
        p.consume(Tokenizer.ASSIGN(), "Expect ':=' after pattern of while val loop");
        val matched := expr(p);
        p.consume(Tokenizer.DO(), "Expect 'do' before while loop body");
        val body := block_expr(p);
        val resulting_expr := Ast.WhileValExpr(pat, matched, body, Ast.late_type(), Ast.late_namespace(), Ast.late_type());
        p.wrap_sugared_expr(resulting_expr)
    end else do 
        val cond := expr(p);
        p.consume(Tokenizer.DO(), "Expect 'do' before while loop body");
        val body := block_expr(p);
        Ast.WhileExpr(cond, body, Ast.late_namespace(), Ast.late_type())
    end
end

fun for_loop(p : Parser) : Ast.Expr do 
    val loop_variable_unconverted := expr(p);
    val loop_variable := convert_setter(loop_variable_unconverted);
    p.consume(Tokenizer.IN(), "Expect 'in' after loop variables");
    val iterated := expr(p);
    p.consume(Tokenizer.DO(), "Expect 'do' before for loop body");
    val body := block_expr(p);
    Ast.ForExpr(loop_variable, iterated, body, Ast.late_namespace(), Ast.late_type(), Ast.late_type())
end

// Expects that starting do is already consumed
fun block_expr(p : Parser) : Ast.Expr do 
    val stmts : Ast.Stmt[] := [];
    var end_expr := None.[Ast.Expr]();
    var no_end_expr_found := true;
    while no_end_expr_found and !p.matches_type(Tokenizer.END()) do 
        match block_part(p) do 
            case Statement(st) := do 
                stmts.push(st);
            end;
            case Expression(e) := do 
                end_expr := Some.[Ast.Expr](e);
                p.consume(Tokenizer.END(), "Expect block to end with 'end'");
                no_end_expr_found := false;
            end;
        end;
    end;
    Ast.BlockExpr(stmts, end_expr, Ast.late_type(), Ast.late_namespace())
end

fun block_part(p : Parser) : Ast.BlockPart do 
    fun potential_end_expr() : Ast.BlockPart do 
        val expression := expr(p);
        if p.matches_type(Tokenizer.SEMICOLON()) then do 
            Ast.Statement(Ast.ExprStmt(expression))
        end else if p.matches_type(Tokenizer.ASSIGN()) then do 
            Ast.Statement(assign_stmt_to(p, expression))
        end else do 
            Ast.Expression(expression)
        end
    end;
    if is_stmt_start(p) then do 
        Ast.Statement(stmt(p))
    end else if val IF() := p.peek().kind then do 
        val pos := p.pos;
        p.next();
        if val VAL() := p.peek().kind then do 
            p.pos := pos;
            potential_end_expr()
        end else do 
            val cond := expr(p);
            if p.matches_type(Tokenizer.DO()) then do 
                val body := block_expr(p);
                Ast.Statement(Ast.IfStmt(cond, body))
            end else do 
                p.pos := pos;
                potential_end_expr()
            end
        end
    end else do 
        potential_end_expr()
    end
end

fun assign_stmt_to(p : Parser, unconverted_setter : Ast.Expr) : Ast.Stmt do 
    val value := expr(p);
    p.consume(Tokenizer.SEMICOLON(), "Expect ':' after assignment");
    val setter := convert_setter(unconverted_setter);
    Ast.SetStatement(setter, value)
end

fun convert_setter(s : Ast.Expr) : Ast.Setter := match s do 
    case Identifier(name, ?) := Ast.Variable(name);
    case WildCardExpression() := Ast.WildcardSetter();
    case TupleExpr(subexprs, lt) := Ast.TupleSetter(for subexpr in subexprs yield convert_setter(subexpr) end, lt);
    case PropertyExpr(obj, name, ?, ?, ?) := do 
        Ast.Property(obj, name, Ast.late_type())
    end;
    case IndexExpr(indexed, index, ?) := Ast.IndexSetter(indexed, index);
    case ? := panic("Invalid setter: "+s);
end;

fun convert_pattern(p : Ast.Expr) : Ast.Pattern := match p do 
    case NumberLiteral(n) := Ast.NumericPattern(n);
    case StringLiteral(s) := Ast.StringPattern(s);
    case Boolean(b) := Ast.BooleanPattern(b);
    case Identifier(i, ?) := Ast.NamePattern(i);
    case TupleExpr(exprs, ?) := Ast.TuplePattern(for e in exprs yield convert_pattern(e) end);
    case FunctionCall(callee, arg_exprs) := do 
        val Identifier(name, ?) := callee else panic("Invalid constructor: "+callee);
        Ast.ConstructorPattern(name, for arg in arg_exprs yield convert_pattern(arg) end, Util.LateInitialized.[Ast.EnumConstructor](), Ast.late_type(), Util.LateInitialized.[Ast.TyInfo]())
    end;
    case WildCardExpression() := Ast.WildcardPattern();
    case ? := panic("Invalid pattern: "+p);
end;

fun is_stmt_start(p : Parser) : Bool := is_decl_start(p) or 
                                        p.peek().kind = Tokenizer.SEMICOLON();

// Expects that if is already consumed
fun if_expr(p : Parser) : Ast.Expr do 
    if p.matches_type(Tokenizer.VAL()) then do 
        val pat := pattern(p);
        p.consume(Tokenizer.ASSIGN(), "Expect := after pattern of if val expression");
        val matched := expr(p);
        p.consume(Tokenizer.THEN(), "Expect then branch after if val condition");
        val thenBranch := expr(p);
        p.consume(Tokenizer.ELSE(), "Expect else branch in if val expression");
        val elseBranch := expr(p);
        p.wrap_sugared_expr(Ast.IfValExpr(
                        Ast.late_type(), 
                        pat, matched, 
                        thenBranch, elseBranch, 
                        Ast.late_namespace(), Ast.late_type()))
    end else do 
        val cond := expr(p);
        p.consume(Tokenizer.THEN(), "Expect then branch after if condition");
        val thenBranch := expr(p);
        p.consume(Tokenizer.ELSE(), "Expect else branch in if expression");
        val elseBranch := expr(p);
        Ast.IfExpr(Ast.late_type(), cond, thenBranch, elseBranch)
    end
end

fun literal(p : Parser) : Ast.Expr :=
    if p.matches_type(Tokenizer.NUMBER_LITERAL()) then do 
        val token := p.previous();
        Ast.NumberLiteral(number(token.src))
    end else if p.matches_type(Tokenizer.STRING_LITERAL()) then do 
        val token := p.previous();
        Ast.StringLiteral(token.src)
    end else if p.matches_type(Tokenizer.TRUE()) then do 
        Ast.Boolean(true)
    end else if p.matches_type(Tokenizer.FALSE()) then do 
        Ast.Boolean(false)
    end else if p.matches_type(Tokenizer.IDENTIFIER()) then do 
        val token := p.previous();
        Ast.Identifier(token.src, Ast.late_type())
    end else if p.matches_type(Tokenizer.NULL()) then do 
        Ast.NullLiteral()
    end else if p.matches_type(Tokenizer.LPAREN()) then do 
        tuple(p)
    end else if p.matches_type(Tokenizer.LBRACKET()) then do
        list(p)
    end else if p.matches_type(Tokenizer.FUN()) then do
        val (params, return_type, body) := end_of_function(p, false);
        Ast.FunctionExpr(params, return_type, body, Ast.late_namespace())
    end else if p.matches_type(Tokenizer.VALUE_THIS()) then do 
        Ast.ThisExpr()
    end else if p.matches_type(Tokenizer.QUESTION_MARK()) then do 
        Ast.WildCardExpression()
    end else do 
        panic(p.err("Invalid literal: "+p.peek().kind))
    end;

fun list(p : Parser) : Ast.Expr do
    val parts : Ast.Expr[] := [];
    if !p.matches_type(Tokenizer.RBRACKET()) do 
        parts.push(expr(p));
        if p.matches_type(Tokenizer.DOTS()) then do 
            val start := parts.pop();
            val end_expr := expr(p);
            p.consume(Tokenizer.RBRACKET(), "Expect closing ']' after range expression");
            return Ast.RangeExpr(start, end_expr);
        end else do 
            while !p.matches_type(Tokenizer.RBRACKET()) do 
                p.consume(Tokenizer.COMMA(), "Expect ',' to separate list parts");
                parts.push(expr(p));
            end
        end
    end
    Ast.ListExpr(parts, Ast.late_type())
end

fun tuple(p : Parser) : Ast.Expr do 
    val exprs : Ast.Expr[] := [];
    var needs_comma := false;
    while !p.matches_type(Tokenizer.RPAREN()) do 
        if needs_comma do 
            p.consume(Tokenizer.COMMA(), "Expect ',' to separate tuple parts");
        end
        exprs.push(expr(p));
        needs_comma := true;
    end;
    if exprs.length = 1 then 
        exprs[0]
    else 
        Ast.TupleExpr(exprs, Ast.late_type())
end

fun type_literal(p : Parser) : Ast.Type do
    var left := if p.matches_type(Tokenizer.NUMBER()) then
        Ast.NumberT()
    else if p.matches_type(Tokenizer.STRING()) then 
        Ast.StringT()
    else if p.matches_type(Tokenizer.BOOLEAN()) then 
        Ast.BooleanT()
    else if p.matches_type(Tokenizer.VOID()) then 
        Ast.VoidT()
    else if p.matches_type(Tokenizer.TYPE_FUN()) then do 
        p.consume(Tokenizer.LPAREN(), "Expect '(' before parameter types of function type");
        val arg_types : Ast.Type[] := [];
        var needs_comma := false;
        while !p.matches_type(Tokenizer.RPAREN()) do 
            if needs_comma do 
                p.consume(Tokenizer.COMMA(), "Expect parameter types to be separated by ','");
            end;
            arg_types.push(type_literal(p));
            needs_comma := true;
        end;
        p.consume(Tokenizer.COLON(), "Expect ':' before function return type");
        val ret_type := type_literal(p);
        Ast.Function([], arg_types, ret_type)
    end else if p.matches_type(Tokenizer.LPAREN()) then do 
        val types : Ast.Type[] := [];
        var needs_comma := false;
        while !p.matches_type(Tokenizer.RPAREN()) do 
            if needs_comma do 
                p.consume(Tokenizer.COMMA(), "Expect tuple type parts to be separated by ','");
            end
            types.push(type_literal(p));
            needs_comma := true;
        end;
        if types.length = 1 then 
            types[0]
        else 
            Ast.Tuple(types)
    end else if p.matches_type(Tokenizer.IDENTIFIER()) then do 
        var last_ident := p.previous().src;
        val path : String[] := [];
        while p.matches_type(Tokenizer.DOT()) do 
            path.push(last_ident);
            last_ident := p.consume(Tokenizer.IDENTIFIER(), "Expect accessed name after '.'").src;
        end;
        if path.length = 0 
            then Ast.Name(last_ident, Ast.late_namespace())
            else Ast.ModuleAccess(path, last_ident, Util.LateInitialized.[Ast.Type]())
    end else do         
        panic("Invalid type: "+p.peek().kind)
    end;

    while p.matches_type(Tokenizer.LBRACKET()) or p.matches_type(Tokenizer.LPAREN()) do
        if p.previous().kind = Tokenizer.LBRACKET() then do 
            left := Ast.ListOf(left);
            p.consume(Tokenizer.RBRACKET(), "Expect ']' after '[' in list type");
        end else do
            val arg_tys: Ast.Type[] := []; 
            var need_comma := false;
            while !p.matches_type(Tokenizer.RPAREN()) do 
                if need_comma do p.consume(Tokenizer.COMMA(), "Expect ',' between type parameters"); end;
                arg_tys.push(type_literal(p));
                need_comma := true;
            end;
            left := Ast.Applied(left, arg_tys);
        end;
    end;
    left
end
