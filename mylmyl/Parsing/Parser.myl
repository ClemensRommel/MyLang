module Parsing.Parser;

import Tokenizer := Parsing.Tokenizer;
import Ast := Syntax.Ast;
import Util;
import Env := Syntax.Env;
import Decl := Parsing.Decl;

class Parser where 
    val tokens : Tokenizer.Token[];
    var pos : Number;

    val undesugared_exprs : Ast.Mut(Ast.Expr)[] := [];
    val undesugared_decls : Ast.Mut(Ast.Decl)[] := [];
    val undesugared_stmts : Ast.Mut(Ast.Stmt)[] := [];

    new(source : String) do
        this.tokens := Tokenizer.tokenize_all(source);
        this.pos := 0;
    end;

    fun next() : Tokenizer.Token do 
        val token := this.tokens[this.pos];
        this.pos := this.pos + 1;
        token
    end

    fun peek() : Tokenizer.Token := this.tokens[this.pos];
    fun peekNext() : Tokenizer.Token := this.tokens[this.pos+1];

    fun consume(t : Tokenizer.TokenType, error : String) : Tokenizer.Token do 
        val nxt := this.next();
        if nxt.kind != t do
            panic("["+(nxt.pos.line+1)+":"+nxt.pos.collumn+"]: Unexpected "+nxt.kind+": "+error);
        end;
        nxt
    end

    fun matches_type(t : Tokenizer.TokenType) : Bool do 
        if this.peek().kind = t then do 
            this.pos := this.pos + 1;
            true
        end else do 
            false
        end
    end

    fun previous() : Tokenizer.Token := this.tokens[this.pos - 1];
    fun at_end() : Bool := this.peek().kind = Tokenizer.EOF();

    fun wrap_sugared_expr(e : Ast.Expr) : Ast.Expr do 
        val mut_expr := Ast.Mut.[Ast.Expr](e);
        this.undesugared_exprs.push(mut_expr);
        Ast.DesugarableExpr(mut_expr)
    end
    fun wrap_sugared_decl(d : Ast.Decl) : Ast.Decl do 
        val mut_decl  := Ast.Mut.[Ast.Decl](d);
        this.undesugared_decls.push(mut_decl);
        Ast.DesugarableDecl(mut_decl)
    end
    fun wrap_sugared_stmt(s : Ast.Stmt) : Ast.Stmt do 
        val mut_stmt := Ast.Mut.[Ast.Stmt](s);
        this.undesugared_stmts.push(mut_stmt);
        Ast.DesugarableStmt(mut_stmt)
    end

    fun err(str: String): String do 
        val nxt := this.peek();
        "["+(nxt.pos.line+1)+":"+nxt.pos.collumn+"]:"+str
    end
end;

fun parse(source : String) : (Ast.Program, (Ast.Mut(Ast.Expr)[], Ast.Mut(Ast.Decl)[], Ast.Mut(Ast.Stmt)[])) do 
    val parser := Parser(source);
    val prg := program(parser); 
    (prg, (parser.undesugared_exprs, parser.undesugared_decls, parser.undesugared_stmts))
end

fun program(p : Parser) : Ast.Program do 
    val prgm := Ast.Program();
    parse_imports(p, prgm);
    while !p.at_end() do 
        prgm.decls.push(Decl.decl(p));
    end;
    prgm
end

fun parse_imports(p : Parser, prgm : Ast.Program) do 
    if p.matches_type(Tokenizer.MODULE()) do 
        p.consume(Tokenizer.IDENTIFIER(), "Expect module name after module declaration");
        while p.matches_type(Tokenizer.DOT()) do 
            p.consume(Tokenizer.IDENTIFIER(), "Expect submodule name after '.'");
        end;
        p.consume(Tokenizer.SEMICOLON(), "Expect ';' after module declaration");
    end
    while p.matches_type(Tokenizer.IMPORT()) do 
        prgm.imports.push(import_decl(p));
    end;
end

fun import_decl(p : Parser) : Ast.Import do 
    val parts : String[] := [];
    parts.push(p.consume(Tokenizer.IDENTIFIER(), "Expect identifier as beginning of path after 'import'").src);
    while p.matches_type(Tokenizer.DOT()) do 
        parts.push(p.consume(Tokenizer.IDENTIFIER(), "Expect identifier after '.'").src);
    end;
    if p.matches_type(Tokenizer.ASSIGN()) then do 
        if parts.length != 1 do panic(p.err("Expected single name as import alias, got complex name: "+parts)); end;
        val alias_name := parts[0];
        val imported_parts : String[] := [];
        imported_parts.push(p.consume(Tokenizer.IDENTIFIER(), "Expect identifier as beginnning of path after ':='").src);
        while p.matches_type(Tokenizer.DOT()) do 
            imported_parts.push(p.consume(Tokenizer.IDENTIFIER(), "Expect identifier after '.'").src);
        end;
        p.consume(Tokenizer.SEMICOLON(), "Expect ';' after import declaration");
        Ast.AliasImport(alias_name, imported_parts)
    end else do
        p.consume(Tokenizer.SEMICOLON(), "Expect ';' after import declaration");
        Ast.BasicImport(parts)
    end
end

fun convert_setter(s : Ast.Expr) : Ast.Setter := match s do 
    case Identifier(name, ?) := Ast.Variable(name);
    case WildCardExpression() := Ast.WildcardSetter();
    case TupleExpr(subexprs, lt) := Ast.TupleSetter(for subexpr in subexprs do convert_setter(subexpr) end, lt);
    case PropertyExpr(obj, name, ?, ?, ?) := do 
        Ast.Property(obj, name, Ast.late_type())
    end;
    case IndexExpr(indexed, index, ?) := Ast.IndexSetter(indexed, index);
    case ? := panic("Invalid setter: "+s);
end;

fun convert_pattern(p : Ast.Expr) : Ast.Pattern := match p do 
    case NumberLiteral(n) := Ast.NumericPattern(n);
    case StringLiteral(s) := Ast.StringPattern(s);
    case Boolean(b) := Ast.BooleanPattern(b);
    case Identifier(i, ?) := Ast.NamePattern(i);
    case TupleExpr(exprs, ?) := Ast.TuplePattern(for e in exprs do convert_pattern(e) end);
    case FunctionCall(callee, arg_exprs) := do 
        val Identifier(name, ?) := callee else panic("Invalid constructor: "+callee);
        Ast.ConstructorPattern(name, for arg in arg_exprs do convert_pattern(arg) end, Util.LateInitialized.[Ast.EnumConstructor](), Ast.late_type(), Util.LateInitialized.[Ast.TyInfo]())
    end;
    case WildCardExpression() := Ast.WildcardPattern();
    case ? := panic("Invalid pattern: "+p);
end;